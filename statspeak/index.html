<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-118361649-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-118361649-1');
</script>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
<link rel="stylesheet" type="text/css" href="css/article.css"/>
<title>Statisticians say the darndest things</title>
<!-- META -->
<!-- LinkedIn meta -->
<meta property='og:title' content="Statisticians say the darndest things"/>
<meta property='og:image' content="http://explained.ai/decision-tree-viz/images/knowledge-TD-3-X.png">
<meta property='og:description' content="Decision trees are the fundamental building block of gradient boosting machines and Random Forests(tm), probably the two most popular machine learning models for structured data. Visualizing decision trees is a tremendous aid when learning how these models work and when interpreting models. Unfortunately, current visualization packages are rudimentary and not immediately helpful to the novice. For example, we couldn't find a library that visualizes how decision nodes split up the feature space. So, we've created a general package (part of the animl library) for scikit-learn decision tree visualization and model interpretation."/>
<meta property='og:url' content="http://explained.ai/statspeak/index.html"/>

<!-- Facebook meta -->
<meta property="og:type" content="article" />

<!-- Twitter meta -->
<meta name="twitter:title" content="Statisticians say the darndest things">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@the_antlr_guy">
<meta name="twitter:creator" content="@the_antlr_guy">
<meta name="twitter:description" content="Decision trees are the fundamental building block of gradient boosting machines and Random Forests(tm), probably the two most popular machine learning models for structured data. Visualizing decision trees is a tremendous aid when learning how these models work and when interpreting models. Unfortunately, current visualization packages are rudimentary and not immediately helpful to the novice. For example, we couldn't find a library that visualizes how decision nodes split up the feature space. So, we've created a general package (part of the animl library) for scikit-learn decision tree visualization and model interpretation.">
<meta name="twitter:image" content="http://explained.ai/decision-tree-viz/images/knowledge-TD-3-X.png">
<!-- END META -->
</head>
<body>
<div class="watermark">
<i>Brought to you by <a href='http://explained.ai'>explained.ai</a></i><br>
</div>

<h1>Statisticians say the darndest things</h1>

<p><a href="http://parrt.cs.usfca.edu">Terence Parr</a></p>

<p style="font-size: 80%">(Terence teaches in <a href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science">University of San Francisco's MS in Data Science program</a>. You might know Terence as the creator of the ANTLR parser generator.)
<p>Please send comments, suggestions, or fixes to <a href="mailto:parrt@cs.usfca.edu">Terence</a>.</p>
</p>

<table>
	<tr>
		<th>If a statistician says ...</th><th>They mean ...</th>
	</tr>
	<tr>
		<td>Lasso regularization</td><td>L1 regularization; see <a href="https://twitter.com/chanep/status/1086659470288216070">tweet by Ernest Chan</a></td>
	</tr>
	<tr>
		<td>Ridge regression</td><td>L2 regularization; see <a href="https://twitter.com/chanep/status/1086659470288216070">tweet by Ernest Chan</a></td>
	</tr>
	<tr>
		<td>Elastic Net</td><td>L1 and L2 regularization; see <a href="https://twitter.com/chanep/status/1086659470288216070">tweet by Ernest Chan</a></td>
	</tr>
	<tr>
		<td>Design matrix</td><td>Matrix of features (or explanatory variables) usually called <i>X</i></td>
	</tr>
	<tr>
		<td>Response or dependent variable</td><td>Target variable usually called <i>y</i> </td>
	</tr>
	<tr>
		<td>Independent variables</td><td>Features or explanatory variables</td>
	</tr>
	<tr>
		<td>Regression</td><td></td>
	</tr>
	<tr>
		<td>Logistic regression</td><td></td>
	</tr>
	<tr>
		<td>ROC (Receiver operating characteristic) curve</td><td>Graph of true positive vs false positive rates</td>
	</tr>
	<tr>
		<td>Type I, Type II errors</td><td>False positive and false negative</td>
	</tr>
	<tr>
		<td>Bias-variance</td><td>underfit-overfit</td>
	</tr>
	<tr>
		<td>Mean</td><td>average</td>
	</tr>
	<tr>
		<td>Sensitivity and specificity</td><td>True positive and true negative rates</td>
	</tr>
	<tr>
		<td>Nonparametric</td><td>Hugely parametric (lots of parameters)</td>
	</tr>
	<tr>
		<td>Model selection</td><td>Feature selection</td>
	</tr>
	<tr>
		<td>Significant</td><td>Statistically distinguishable; says nothing of magnitude</td>
	</tr>
	<tr>
		<td>Normal</td><td>Gaussian</td>
	</tr>
	<tr>
		<td>Bootstrap</td><td>Randomly select observations with replacement</td>
	</tr>
	<tr>
		<td></td><td></td>
	</tr>
	<tr>
		<td></td><td></td>
	</tr>
	<tr>
		<td></td><td></td>
	</tr>
	<tr>
		<td></td><td></td>
	</tr>
	<tr>
		<td></td><td></td>
	</tr>
	<tr>
		<td></td><td></td>
	</tr>
</table>

</body>
</html>
